---
title: "Heart Failure/Disease Prediction"
author: "Himangshu Raj Bhantana"
date: "12/3/2021"
geometry: margin=1cm
output: pdf_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary

This is a study to see whether certain types of chest symptoms are severe and linked to heart disease, as well as to anticipate general causes of heart disease. As an analytical method, a logistic regression model was used. As a result of this investigation, several chest symptoms variables, as well as other predictors, were statistically examined, leading to the discovery of general causes of heart disease.

## Introduction

Cardiovascular diseases (CVDs) are the leading cause of death globally, killing an estimated 17.9 million people each year and accounting for 31% of all fatalities. Heart attacks or strokes account for four out of every five CVD fatalities, with those under the age of 70 accounting for one-third of these deaths. This study delves deeply into the true causes of heart disease/failure. Some of the specific questions that will be addressed in this study are as follows: 

* Determining which sorts of chest symptoms are severe and connected with heart disease, as well as predicting general causes of heart disease.

The summary statistics for the continuous predictor for our heart dataset are shown in the table below.
```{r, results = "asis",echo=FALSE,header= FALSE, message = FALSE, warning = FALSE, echo=FALSE}

heart <- read.csv("~/Downloads/heart.csv")

library(stargazer)
attach(heart)
stargazer(heart,header=FALSE,title="Summary Statistics", type='latex')

```

## Data

Before getting into the data analysis for this study, the heart dataset was created by combining multiple datasets that were previously available separately but had not been integrated. This heart dataset combines five previous heart datasets with 11 similar features to provide the largest heart disease dataset available for research purposes to date. 

The following are the five datasets used for curation: 

* Cleveland has had 303 observations, while Hungary has had 294 observations. 

* Switzerland has 123 observations. 

* At Long Beach, Virginia, 200 observations were made, with 270 observations in the Stalog (Heart) Data Set. 

There were 1190 observations in total, 272 of which were duplicated, for a total of 918 observations in the final dataset, with a mix of categorical and continuous variables, which was examined. Because not all variables, such as RestingEC and ExerciseAngina, were applied in this study, since we were primarily interested in heart disease and different forms of chest pain, these variables were also omitted owing to their obviousness in providing the answer straight away before moving on to the next phase; because this was obvious and had a role, we wanted to investigate how the remainder of the variables related to heart disease.

Here is a list of the variables and their descriptions to help us follow along with the rest of the study's process:

| **Variable** | **Description** |
|  :---:   |    :---:    |
|Age | Age of the patient [years]|
|Sex | Sex of the patient [M: Male, F: Female]|
|ChestPainType | Chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]|
|RestingBP | Resting blood pressure [mm Hg]|
|Cholesterol | Serum cholesterol [mm/dl]|
|FastingBS | Fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]|
|RestingEC | Resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)| |LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]|
|MaxHR | Maximum heart rate achieved [Numeric value between 60 and 202]|
|ExerciseAngina | Exercise-induced angina [Y: Yes, N: No]|
|Oldpeak | Oldpeak = ST [Numeric value measured in depression]|
|ST_Slope| The slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]|
|HeartDisease| Output class [1: heart disease, 0: Normal]|

Beginning with exploratory data analysis on the updated heart dataset to establish the model and predictors. A factor has been applied to our category variable. The continuous variable was also mean-centered to avoid multicollinearity. Our model is shown in the form of a box plot for the continuous predictor in contrast to our categorical response variable, as well as a table with a CHI-test for comparing both of our categorical variables. Performing this exploratory data analysis allows us to determine if the factors are independent or not. One of the most intriguing EDAs I discovered was the Heart Disease VS Age EDA, which illustrates that as individuals age, they are more likely to get heart disease, which can lead to heart failure.
```{r, results= "asis", echo=FALSE, message=FALSE, warning=FALSE, fig.width=5, fig.height=3.7,figures-side1699, fig.show="hold", header= FALSE, message = FALSE,warning = FALSE, echo=FALSE,  out.width="39%",fig.align="center"}
library(arm)
library(pROC)
library(e1071)
library(caret)
library(ggplot2)
require(gridExtra)

heart <- read.csv("~/Downloads/heart.csv")

##Summary


#Factoring Categorical Variables
heart$Sex<- factor(heart$Sex)
heart$ChestPainType<- factor(heart$ChestPainType)
heart$ST_Slope<- factor(heart$ST_Slope)
heart$ExerciseAngina<- factor(heart$ExerciseAngina)
heart$RestingECG<- factor(heart$RestingECG)
heart$HeartDisease<-factor(heart$HeartDisease)

#Mean center the numerical predictors to avoid Mutli.Col
heart$RestingBP <- heart$RestingBP - mean(heart$RestingBP)
heart$Cholesterol <- heart$Cholesterol - mean(heart$Cholesterol)
heart$FastingBS <- heart$FastingBS - mean(heart$FastingBS)
heart$MaxHR <- heart$MaxHR - mean(heart$MaxHR)
heart$Oldpeak <- heart$Oldpeak - mean(heart$Oldpeak)



table(heart$HeartDisease)

#factor+conti=boxplot, continous+continous= geompoint, factor+factor=table
#EDA
# Geom_box Plot for Factor and Continious
library(viridis)

  ggplot(heart, aes(x=HeartDisease,y=Age, fill=HeartDisease))+geom_boxplot()+   scale_fill_brewer(palette="Blues")+
  labs(title="Age vs Heart Disease",x="HeartDisease",y="Age") +  theme_bw() + 
  theme(legend.position="none",axis.text.x = element_text(angle = 0,size = 6)) + 
  theme(plot.title = element_text(face = "bold", size = 9),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank())
```

The box plots below indicate the interaction between the continuous variable and the categorical response variable, which is shown to be independent in the majority of cases:

```{r, results = "hide",fig.width=7, fig.height=5,fig.align='center',figures-side1687, fig.show="hold", out.width="70%", header= FALSE, message = FALSE,warning = FALSE, echo=FALSE}
library(arm)
library(pROC)
library(e1071)
library(caret)
library(ggplot2)
require(gridExtra)

heart <- read.csv("~/Downloads/heart.csv")

##Summary


#Factoring Categorical Variables
heart$Sex<- factor(heart$Sex)
heart$ChestPainType<- factor(heart$ChestPainType)
heart$ST_Slope<- factor(heart$ST_Slope)
heart$ExerciseAngina<- factor(heart$ExerciseAngina)
heart$RestingECG<- factor(heart$RestingECG)
heart$HeartDisease<-factor(heart$HeartDisease)

#Mean center the numerical predictors to avoid Mutli.Col
heart$RestingBP <- heart$RestingBP - mean(heart$RestingBP)
heart$Cholesterol <- heart$Cholesterol - mean(heart$Cholesterol)
heart$FastingBS <- heart$FastingBS - mean(heart$FastingBS)
heart$MaxHR <- heart$MaxHR - mean(heart$MaxHR)
heart$Oldpeak <- heart$Oldpeak - mean(heart$Oldpeak)



table(heart$HeartDisease)

#factor+conti=boxplot, continous+continous= geompoint, factor+factor=table
#EDA
# Geom_box Plot for Factor and Continious
library(viridis)



a<-ggplot(heart, aes(x=HeartDisease,y=RestingBP, fill=HeartDisease))+geom_boxplot()+   scale_fill_brewer(palette="Blues")+
  labs(title="RestingBP vs Heart Disease",x="HeartDisease",y="RestingBP") +  theme_bw() + 
  theme(legend.position="none",axis.text.x = element_text(angle = 0,size = 6)) + 
  theme(plot.title = element_text(face = "bold", size = 9),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank())
  
b<-ggplot(heart, aes(x=HeartDisease,y=Cholesterol, fill=HeartDisease))+geom_boxplot()+   scale_fill_brewer(palette="Blues")+
  labs(title="Cholesterol vs Heart Disease",x="HeartDisease",y="Cholesterol") +  theme_bw() + 
  theme(legend.position="none",axis.text.x = element_text(angle = 0,size = 6)) + 
  theme(plot.title = element_text(face = "bold", size = 9),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank())
  
c<-ggplot(heart, aes(x=HeartDisease,y=FastingBS, fill=HeartDisease))+geom_boxplot()+
     scale_fill_brewer(palette="Blues")+
 labs(title="FastingBS vs Heart Disease",x="HeartDisease",y="FastingBS") +  theme_bw() + 
  theme(legend.position="none",axis.text.x = element_text(angle = 0,size = 6)) + 
  theme(plot.title = element_text(face = "bold", size = 9),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank())
  
d<-ggplot(heart, aes(x=HeartDisease,y=MaxHR, fill=HeartDisease))+geom_boxplot()+
     scale_fill_brewer(palette="Blues")+
 labs(title="MaxHR vs Heart Disease",x="HeartDisease",y="MaxHR") +  theme_bw() + 
  theme(legend.position="none",axis.text.x = element_text(angle = 0,size = 6)) + 
  theme(plot.title = element_text(face = "bold", size = 9),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank())
  
e<-ggplot(heart, aes(x=HeartDisease,y=Oldpeak,fill=HeartDisease))+geom_boxplot()+
     scale_fill_brewer(palette="Blues")+
 labs(title="Oldpeak vs Heart Disease",x="HeartDisease",y="Oldpeak") +  theme_bw() + 
  theme(legend.position="none",axis.text.x = element_text(angle = 0,size = 6)) + 
  theme(plot.title = element_text(face = "bold", size = 9),
    axis.ticks = element_line(colour = "grey70", size = 0.2),
    panel.grid.major = element_line(colour = "grey70", size = 0.2),
    panel.grid.minor = element_blank())
  

grid.arrange(grobs = list(a,b,c,d,e), ncol = 3, main = "Main title")
```

## CHI Test

As we work with tables and the CHI test for association for factor variables, we can see whether or not the factor variables are significant. After completing the CHI test for factor variables, it was determined that the response variable heartdisease association with ST_Slope and sex is statistically significant and independent because the P value is less than 5%.

## Model

Before fitting the model, we must determine if the predictors are random or not, and if not, a transformation must be applied. We use a binned plot to verify the randomness of continuous predictors. The transformation was unnecessary because the continuous predictors were random and no strange patterns were created. Beginning by fitting the first logistic regression model, which includes all categorical and factor variables, as well as significant correlations and other intriguing interactions, just to see if they influence the model or not.

Because we needed significant predictors to provide the best estimation for our query, I picked the Stepwise AIC model, which generated a new logistic regression model with significant predictors. After experimenting with several selection methods, such as forward and stepwise, which provided the same important predictors, I decided to stick with the AIC Model. Although stepwise regression with AIC advised that I add age as a predictor in my final model, it is negligible at p 0.05 after correcting for the other covariates. As a result, we may infer that the addition of the other factors has eliminated the predictive impact of age.

The mathematical regression equation for the final model is: 

```{r,echo=FALSE}
# <!-- $$ -->
# <!-- Pr(Y_i=1|X_i) = {\frac{exp(\beta_0 + \beta_1Sex + \beta_2ChestPainType + \beta_3ST_Slope + \beta_4Cholesterol+ \beta_5Sex + \beta_6FastingBS +  -->
# <!--   \beta_7MaxHR )} -->
# <!-- $$ -->
# <!-- $$ -->
# <!--    {(\beta_8Oldpeak+ \beta_9Cholesterol:FastingBS+\beta_10Cholesterol:MaxHR+\beta_11FastingBS:MaxHR)}} -->
# <!-- $$ -->
library(equatiomatic)
library(pROC)
library(e1071)
library(caret)
library(ggplot2)
require(gridExtra)
newone3<-glm( HeartDisease ~ Sex  +ChestPainType+ ST_Slope + Cholesterol + 
                FastingBS + MaxHR + Oldpeak + Cholesterol:FastingBS + Cholesterol:MaxHR + 
                FastingBS:MaxHR , family = binomial, 
              data = heart)
extract_eq(newone3, wrap = TRUE)

```
The following is a summary of our model selection for our new final logistic regression model:

```{r,results = "asis",header= FALSE, message = FALSE, warning = FALSE, echo=FALSE}
library(stargazer)
stargazer(newone3,title= "Results", header=FALSE, type='latex',digits = 2,no.space = TRUE,column.sep.width = "3pt",single.row=TRUE)
```

We have yet to determine whether or not there is multicollinearity. When we test the VIP of our final model for multicollinearity, we see that the value for each variable does not exceed the value of 10. This eliminates the need to be worried about multicollinearity.

### Model Assessment

To evaluate our model, we first generate a binned residual plot of projected probabilities vs. residuals. We can observe that practically all of the observations are inside our confidence interval bands and are dispersed quite randomly. Fitted residuals have points randomly spread about 0 on the Y axis, and there is no evident linear trend, however outliers occur. There is also some clustering on the X axis. While this does not contradict our assumptions, it may imply that the model is lacking certain predictors.

```{r, results = "hide",fig.width=5, fig.height=3.7,figures-side71, fig.show="hold", header= FALSE, message = FALSE,warning = FALSE, echo=FALSE,  out.width="33%",fig.align="center"}
residy <- residuals(newone3)
binnedplot(x=fitted(newone3),y=residy,xlab="Fitted")
binnedplot(x=heart$MaxHR,y=residy,xlab="MaxHR")
binnedplot(x=heart$Oldpeak,y=residy,xlab="Oldpeak")
binnedplot(x=heart$RestingB,y=residy,xlab="RestingB")


```
We also plot residuals against each continuous predictor to determine if there is any pattern that our model has missed. When we may conclude that there are no trends when plotted versus residuals
```{r, results = "hide",fig.width=5, fig.height=3.7,figures-side72, fig.show="hold", header= FALSE, message = FALSE,warning = FALSE, echo=FALSE,  out.width="33%",fig.align="center"}

# binnedplot(x=heart$Cholesterol,y=residy,xlab="Cholesterol")
```

### Model Validation
We may now go to model validation. To validate the model, the confusion matrix will be utilized. The accuracy of the model is 85.8 percent, the sensitivity is 86.4 percent, and the specificity is 85.12 percent. The ROC curve shows that using a probability threshold of 0.5 helps us maximize our model's predictions. These numbers appear to be correct, even if it looks like they haven't been totally balanced out, which is impossible. This might be better, but considering the type of data we're working with, our current AUC is adequate for the time being.

The ROC curve is depicted here, and its area is 0.458, illustrating how well our model predicts.

```{r, results= "asis", echo=FALSE, message=FALSE, warning=FALSE, fig.width=5, fig.height=3.7,figures-side77, fig.show="hold", header= FALSE, message = FALSE,warning = FALSE, echo=FALSE,  out.width="33%",fig.align="center"}
Confy <- confusionMatrix(as.factor(ifelse(fitted(newone3) >= 0.566, "1","0")),
                         as.factor(heart$HeartDisease),positive = "1")
#Confy$table
#Confy$overall["Accuracy"];
#Confy$byClass[c("Sensitivity","Specificity")] #True positive rate and True negative rate

#mean(heart$HeartDisease)
#Confy <- confusionMatrix(as.factor(ifelse(fitted(newone) >= mean(heart$HeartDisease), "1","0")),
                         #as.factor(heart$HeartDisease),positive = "1")
a<-roc(heart$HeartDisease,fitted(newone3),plot=T,print.thres="best",legacy.axes=T,
    print.auc =T,col="red3")
```


Taking the coefficients for the significant predictors and holding everything else constant yields the following results on average:

* For every unit increase in OldPeak over its mean, the risk of heart disease increases by 1.68 times.
* FastingBS increases the risk of heart disease by 3.4 times for every unit over the mean.
* Every unit increase in MaxHR above the mean increases the risk of heart disease by 0.99 times.
* If all other variables stay constant and the patient has an average cholesterol level, the risk of heart disease increases by 0.99 times.
* Patients with chestpaintypeATA are 0.13 times more likely to have cardiac disease than patients with chestpaintypeASY.
* Patients with chestpaintypeNAP are 0.16 times more likely to have cardiac disease than patients with chestpaintypeASY.
* Patients with chestpaintypeTA are 0.18 times more likely to have cardiac disease than patients with chestpaintypeASY.
* Patients with ST SlopeFlat are 4.4 times more likely to have heart disease than those with ST SlopeDown.
* Patients with ST SlopeFlat are 4.4 times more likely to have heart disease than those with ST SlopeDown.
* Patients with ST SlopeUp are 0.32 times more likely to have heart disease than those with ST SlopeDown.
* Patients with ST SlopeUp are 0.32 times more likely to have heart disease than those with ST SlopeDown.
* Males are five times more likely to have heart disease than females.

## Conclusion

To summarize our study's questions, we can draw the conclusion that patients with chest pains such as chestpaintypeATA, chestpaintypeNAP, and chestpaintypeTA have strongly connected with heart disease, which leads to heart failure; additional factors such as whether patients have an oldpeak, fasting blood sugar, cholesterol, and ST Slope Flat and Up are all common factors of heart disease. I'd like to draw our attention to the fact that males are more likely than females to suffer from heart disease or failure.

# Limitations

I noted that the data collection for this type of study is insufficient because logistic regression models require a large data set to provide significant results. Despite the fact that multiple merged data sets were used, I feel that having more data would be more effective in predicting heart failure. I also feel that there are other factors that can alter the prediction and make the study more interesting, such as patients who smoke or do not smoke, genetic inheritance, and many others. 